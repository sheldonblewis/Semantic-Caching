import openai
from sentence_transformers import SentenceTransformers
from sklearn.metrics.pairwise import cosine_similarity



import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

class FaissSemanticSearch:
    def __init__(self, model_name='all-MiniLM-L6-v2', similarity_threshold=0.8):
        """
        Initialize the semantic search using FAISS.
        :param model_name: The SentenceTransformer model for generating embeddings.
        :param similarity_threshold: Minimum similarity score for a result to be considered.
        """
        self.similarity_threshold = similarity_threshold
        self.model = SentenceTransformer(model_name)
        self.embeddings = None
        self.index = None
        self.prompts = []

    def build_index(self):
        """Builds the FAISS index from the stored embeddings."""
        if self.embeddings is None:
            raise ValueError("No embeddings to index. Add prompts first.")
        # Dimension of embeddings
        d = self.embeddings.shape[1]
        self.index = faiss.IndexFlatL2(d)
        self.index.add(self.embeddings)

    def add_prompts(self, prompts):
        """
        Adds new prompts to the index.
        :param prompts: List of prompt strings.
        """
        new_embeddings = np.array(self.model.encode(prompts))
        if self.embeddings is None:
            self.embeddings = new_embeddings
        else:
            self.embeddings = np.vstack((self.embeddings, new_embeddings))
        self.prompts.add(prompts)

    def search(self, query, top_k=5):
        """
        Searches for semantically similar prompts.
        :param query: The query string.
        :param top_k: Number of nearest neighbors to retrieve.
        :return: List of tuples (similarity_score, prompt) for the top_k results.
        """
        if self.index is None:
            raise ValueError("Index not built. Build the index before searching.")
        
        query_embedding = np.array(self.model.encode([query]))
        distances, indices = self.index.search(query_embedding, top_k)
        
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if dist < self.similarity_threshold:  # Distances are squared L2 norms, smaller is better
                similarity = 1 / (1 + dist)  # Convert to similarity score (optional)
                results.append((similarity, self.prompts[idx]))
        return results

# Example Usage
semantic_search = FaissSemanticSearch(similarity_threshold=0.3)  # Lower threshold for L2 norms

# Adding prompts
prompts = {
    "What is the capital of France?": "Paris",
    "Tell me about Paris.": "French",
    "Explain quantum physics.": "Complicated",
    "How do neural networks work?": "Also complicated"
}
semantic_search.add_prompts(prompts)

# Build the FAISS index
semantic_search.build_index()

# Querying the index
query = "What is the main city of France?"
results = semantic_search.search(query, top_k=3)

# Display results
for score, prompt in results:
    print(f"Similarity: {score:.4f}, Prompt: {prompt}")


for i in range(len(results)):
    if results[i][0] > 0.8:
        print(prompts[results[i][1]])
    else:
        try:
            response = openai.Completion.create(
                engine="text-davinci-003",
                prompt=prompt,
                max_tokens=100,
                temperature=0.7
            )
            print(response.choices[0].text.strip())
        except Exception as e:
            print(f"Error calling OpenAI API: {e}")
            print("Error: Unable to get a response from OpenAI.")
